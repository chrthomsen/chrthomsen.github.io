
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Beginner Guide &#8212; pygrametl 2.7 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Database" href="../examples/database.html" />
    <link rel="prev" title="Install Guide" href="install.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="beginner-guide">
<span id="beginner"></span><h1>Beginner Guide<a class="headerlink" href="#beginner-guide" title="Permalink to this heading">¶</a></h1>
<p>The following is a small guide for users new to pygrametl. It shows the main
constructs provided by pygrametl and how to use them to create a simple ETL
flow for a made-up example. The example is a toy data warehouse for a chain of
book stores and is shown below as <a class="reference internal" href="#dwexample"><span class="std std-ref">Data Warehouse example</span></a>. The warehouse has one fact
table and three dimensions organized in a star schema. The fact table stores
facts about how many of each book is sold each day. The book dimension stores
the name and genre of each book sold, the location dimension stores the city
and region of the stores, and the time dimension stores the date of each sale.
To keep the example simple, none of the dimensions are snowflaked, nor do they
contain any slowly changing attributes. These are however supported by
pygrametl through <a class="reference internal" href="../api/tables.html#pygrametl.tables.SnowflakedDimension" title="pygrametl.tables.SnowflakedDimension"><code class="xref py py-class docutils literal notranslate"><span class="pre">SnowflakedDimension</span></code></a>,
<a class="reference internal" href="../api/tables.html#pygrametl.tables.TypeOneSlowlyChangingDimension" title="pygrametl.tables.TypeOneSlowlyChangingDimension"><code class="xref py py-class docutils literal notranslate"><span class="pre">TypeOneSlowlyChangingDimension</span></code></a>, and
<a class="reference internal" href="../api/tables.html#pygrametl.tables.SlowlyChangingDimension" title="pygrametl.tables.SlowlyChangingDimension"><code class="xref py py-class docutils literal notranslate"><span class="pre">SlowlyChangingDimension</span></code></a>, respectively. In addition, pygrametl
provides high-level constructs for creating efficient multiprocess or
multithreaded ETL flow, depending on the implementation of Python used (see
<a class="reference internal" href="../examples/parallel.html#parallel"><span class="std std-ref">Parallel</span></a>). pygrametl also simplifies testing by making it easy to define
preconditions and postconditions for each part of an ETL flow without relying
on external files for the input and the expected results (see <a class="reference internal" href="../examples/testing.html#testing"><span class="std std-ref">Drawn Table Testing</span></a>).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When using pygrametl, we strongly recommend using named parameters when
instantiating classes as this improves readability and prevents errors in
the future if the API changes.</p>
</div>
<figure class="align-center" id="id1">
<span id="dwexample"></span><img alt="bookstore data warehouse example" src="../_images/example.svg" /><figcaption>
<p><span class="caption-text">Data Warehouse example</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<section id="input-data">
<h2>Input Data<a class="headerlink" href="#input-data" title="Permalink to this heading">¶</a></h2>
<p>Most pygrametl abstractions either produce, consume, or operate on data in
rows. A row is a Python <code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code> where the names of the row’s columns are
the keys and the values are the data the row contains. For more information
about the data sources provided by pygrametl see <a class="reference internal" href="../examples/datasources.html#datasources"><span class="std std-ref">Data Sources</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The data and Python source code in this guide can be downloaded using the
following <a class="reference external" href="../_static/beginner_guide_data.zip">link</a>.</p>
</div>
<p>The most important data for the warehouse are which books have been sold. This
information can be extracted from the book stores’ sales records which are
stored in the SQLite database sale.sqlite. Of course, storing sales records
from multiple book stores is not a common use-case for SQLite. However, SQLite
is used in this beginner guide as it makes sharing the input data simple and
demonstrates pygrametl’s ability to read and write from any RDBMS that provides
a <span class="target" id="index-0"></span><a class="pep reference external" href="https://peps.python.org/pep-0249/"><strong>PEP 249</strong></a> connection. The data is stored in the table sale as shown below:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>| book:text             | genre:text | store:text | date:date      | sale:int |
| --------------------- | ---------- | ---------- | -------------- | -------- |
| Nineteen Eighty-Four  | Novel      | Aalborg    | 2005/08/05     | 50       |
| Calvin and Hobbes One | Comic      | Aalborg    | 2005/08/05     | 25       |
| The Silver Spoon      | Cookbook   | Aalborg    | 2005/08/14     | 5        |
| The Silver Spoon      | Cookbook   | Odense     | 2005/09/01     | 7        |
| ....                  |            |            |                |          |
</pre></div>
</div>
<p>The book titles and genres are extracted from the <a class="reference external" href="https://www.cs.cmu.edu/~dbamman/booksummaries.html">CMU Book Summary Dataset</a>. As the geographical
information stored in the sales records is limited, the location dimension must
be pre-filled with data from the CSV file region.csv. This file contains data
about cities and regions as shown below (the tabs are added for readability):</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>city,       region
Aalborg,    North Denmark Region
Odense,     Region of Southern Denmark
....
</pre></div>
</div>
</section>
<section id="etl-flow">
<h2>ETL Flow<a class="headerlink" href="#etl-flow" title="Permalink to this heading">¶</a></h2>
<p>The ETL flow is designed to run on CPython and use PostgreSQL as the RDBMS for
the data warehouse. The guide assumes PostgreSQL is already installed and
running. The ETL flow can easily be run on other Python implementations like
Jython. For example, to use Jython the <span class="target" id="index-1"></span><a class="pep reference external" href="https://peps.python.org/pep-0249/"><strong>PEP 249</strong></a> database drivers must simply
be replaced with their <a class="reference external" href="https://jcp.org/en/jsr/detail?id=221">JDBC</a>
equivalents and <a class="reference internal" href="../api/pygrametl.html#pygrametl.ConnectionWrapper" title="pygrametl.ConnectionWrapper"><code class="xref py py-class docutils literal notranslate"><span class="pre">ConnectionWrapper</span></code></a> with
<a class="reference internal" href="../api/jdbcconnectionwrapper.html#pygrametl.JDBCConnectionWrapper.JDBCConnectionWrapper" title="pygrametl.JDBCConnectionWrapper.JDBCConnectionWrapper"><code class="xref py py-class docutils literal notranslate"><span class="pre">JDBCConnectionWrapper</span></code></a>. For more information about running pygrametl
on Jython see <a class="reference internal" href="../examples/jython.html#jython"><span class="std std-ref">Jython</span></a>.</p>
<p>We start by creating the database and tables for the data warehouse in
PostgreSQL using psql. The SQL script example.sql creates the dw database, the
dwuser role with all privileges, and the four tables:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">psql</span> <span class="o">-</span><span class="n">f</span> <span class="n">example</span><span class="o">.</span><span class="n">sql</span>
</pre></div>
</div>
<p>For the ETL flow we start by importing the various functions and classes needed
in this beginner guide. The psycopg2 and sqlite3 database drivers must be
imported so a connection to PostgreSQL and SQLite can be established. The main
pygrametl module is also imported so a <a class="reference internal" href="../api/pygrametl.html#pygrametl.ConnectionWrapper" title="pygrametl.ConnectionWrapper"><code class="xref py py-class docutils literal notranslate"><span class="pre">ConnectionWrapper</span></code></a> can be
created. pyggrametl’s <a class="reference internal" href="../api/datasources.html#module-pygrametl.datasources" title="pygrametl.datasources"><code class="xref py py-mod docutils literal notranslate"><span class="pre">datasources</span></code></a> module is imported so the sales
records (<a class="reference internal" href="../api/datasources.html#pygrametl.datasources.SQLSource" title="pygrametl.datasources.SQLSource"><code class="xref py py-class docutils literal notranslate"><span class="pre">SQLSource</span></code></a>) and CSV file (<code class="xref py py-class docutils literal notranslate"><span class="pre">CSVSource</span></code>) can be read.
Finally, classes for interacting with the fact table (<a class="reference internal" href="../api/tables.html#pygrametl.tables.FactTable" title="pygrametl.tables.FactTable"><code class="xref py py-class docutils literal notranslate"><span class="pre">FactTable</span></code></a>) and
the various dimensions (<a class="reference internal" href="../api/tables.html#pygrametl.tables.CachedDimension" title="pygrametl.tables.CachedDimension"><code class="xref py py-class docutils literal notranslate"><span class="pre">CachedDimension</span></code></a>) are imported from
<a class="reference internal" href="../api/tables.html#module-pygrametl.tables" title="pygrametl.tables"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tables</span></code></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># psycopg2 is a database driver allowing CPython to access PostgreSQL</span>
<span class="kn">import</span> <span class="nn">psycopg2</span>

<span class="c1"># sqlite3 is a database driver allowing CPython to access SQLite</span>
<span class="kn">import</span> <span class="nn">sqlite3</span>

<span class="c1"># pygrametl&#39;s __init__ file provides a set of helper functions and more</span>
<span class="c1"># importantly the class ConnectionWrapper for wrapping PEP 249 connections</span>
<span class="kn">import</span> <span class="nn">pygrametl</span>

<span class="c1"># pygrametl makes it simple to read external data through datasources</span>
<span class="kn">from</span> <span class="nn">pygrametl.datasources</span> <span class="kn">import</span> <span class="n">SQLSource</span><span class="p">,</span> <span class="n">CSVSource</span>

<span class="c1"># Interacting with the dimensions and the fact table is done through a set</span>
<span class="c1"># of classes. A suitable object must be created for each table</span>
<span class="kn">from</span> <span class="nn">pygrametl.tables</span> <span class="kn">import</span> <span class="n">CachedDimension</span><span class="p">,</span> <span class="n">FactTable</span>
</pre></div>
</div>
<p>Then a connection to the database containing the sales records and the data
warehouses is needed. For CPython, these must be <span class="target" id="index-2"></span><a class="pep reference external" href="https://peps.python.org/pep-0249/"><strong>PEP 249</strong></a> connections. As the
data warehouse connection will be shared by multiple pygrametl abstractions, an
instance of <a class="reference internal" href="../api/pygrametl.html#pygrametl.ConnectionWrapper" title="pygrametl.ConnectionWrapper"><code class="xref py py-class docutils literal notranslate"><span class="pre">ConnectionWrapper</span></code></a> is created. The first instance created
of this class is set as the default connection for pygrametl’s abstractions.
This allows pygrametl to be used without having to pass a connection to each
abstraction that needs it. A <a class="reference internal" href="../api/pygrametl.html#pygrametl.ConnectionWrapper" title="pygrametl.ConnectionWrapper"><code class="xref py py-class docutils literal notranslate"><span class="pre">ConnectionWrapper</span></code></a> is not needed for the
connection to the sales database as it is only used by the <code class="xref py py-class docutils literal notranslate"><span class="pre">CSVSource</span></code>,
so in that case, the <span class="target" id="index-3"></span><a class="pep reference external" href="https://peps.python.org/pep-0249/"><strong>PEP 249</strong></a> connection is used directly. For more
information about database connections in pygrametl see <a class="reference internal" href="../examples/database.html#database"><span class="std std-ref">Database</span></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Creates a PEP 249 connection to the sales database. PARSE_DECLTYPES makes</span>
<span class="c1"># sqlite3 return values with the types specified in the database&#39;s schema</span>
<span class="n">sale_conn</span> <span class="o">=</span> <span class="n">sqlite3</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="s2">&quot;sale.sqlite&quot;</span><span class="p">,</span>
        <span class="n">detect_types</span><span class="o">=</span><span class="n">sqlite3</span><span class="o">.</span><span class="n">PARSE_DECLTYPES</span><span class="p">)</span>

<span class="c1"># While SQLite is used in this guide, any RDBMS that provides a PEP 249</span>
<span class="c1"># driver can be used with pygrametl. For example, SQLite can be replaced</span>
<span class="c1"># with PostgreSQL by simply replacing sale_conn with following two lines</span>
<span class="c1"># sale_string = &quot;host=&#39;localhost&#39; dbname=&#39;sale&#39; user=&#39;user&#39; password=&#39;pass&#39;&quot;</span>
<span class="c1"># sale_conn = psycopg2.connect(sale_string)</span>

<span class="c1"># A connection is also created to the data warehouse. The connection is</span>
<span class="c1"># then given to a ConnectionWrapper so it becomes implicitly shared between</span>
<span class="c1"># all the pygrametl abstractions that needs it without being passed around</span>
<span class="n">dw_string</span> <span class="o">=</span> <span class="s2">&quot;host=&#39;localhost&#39; dbname=&#39;dw&#39; user=&#39;dwuser&#39; password=&#39;dwpass&#39;&quot;</span>
<span class="n">dw_conn</span> <span class="o">=</span> <span class="n">psycopg2</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">dw_string</span><span class="p">)</span>

<span class="c1"># Although the ConnectionWrapper is shared automatically between pygrametl</span>
<span class="c1"># abstractions, it is saved in a variable so the connection can be closed</span>
<span class="n">dw_conn_wrapper</span> <span class="o">=</span> <span class="n">pygrametl</span><span class="o">.</span><span class="n">ConnectionWrapper</span><span class="p">(</span><span class="n">connection</span><span class="o">=</span><span class="n">dw_conn</span><span class="p">)</span>
</pre></div>
</div>
<p>To get data into the ETL flow, two data sources are created. One for the
database containing the sales records, and one for the CSV file containing the
region information. For more information about the various data sources
provided by pygrametl see <a class="reference internal" href="../examples/datasources.html#datasources"><span class="std std-ref">Data Sources</span></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># The location dimension stores the name of a location in the column city</span>
<span class="c1"># instead of in the column store as done in the input data from the sales</span>
<span class="c1"># database. By passing SQLSource a sequence of names matching the number of</span>
<span class="c1"># columns in the table it can automatically rename the columns</span>
<span class="n">name_mapping</span> <span class="o">=</span> <span class="s1">&#39;book&#39;</span><span class="p">,</span> <span class="s1">&#39;genre&#39;</span><span class="p">,</span> <span class="s1">&#39;city&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;sale&#39;</span>

<span class="c1"># Extraction of rows from a database using a PEP 249 connection and SQL</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;SELECT book, genre, store, date, sale FROM sale&quot;</span>
<span class="n">sale_source</span> <span class="o">=</span> <span class="n">SQLSource</span><span class="p">(</span><span class="n">connection</span><span class="o">=</span><span class="n">sale_conn</span><span class="p">,</span> <span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span>
        <span class="n">names</span><span class="o">=</span><span class="n">name_mapping</span><span class="p">)</span>

<span class="c1"># Extraction of rows from a CSV file does not require a PEP 249 connection,</span>
<span class="c1"># just an open file handler. pygrametl uses Python&#39;s DictReader for CSV</span>
<span class="c1"># files and assumes the header of the CSV file contains the name of each</span>
<span class="c1"># column. When using CSVSource it is very important to convert the values</span>
<span class="c1"># to the correct type before inserting them into a table through pygrametl.</span>
<span class="c1"># As region.csv is encoded as UTF-8 and contains the non-ASCII characters æ</span>
<span class="c1"># and ø, the encoding open() will use is explicitly set to UTF-8. Of course,</span>
<span class="c1"># if a file uses a different encoding than UTF-8 it should be used instead</span>
<span class="n">region_file_handle</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;region.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="mi">16384</span><span class="p">,</span> <span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>
<span class="n">region_source</span> <span class="o">=</span> <span class="n">CSVSource</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">region_file_handle</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>An object must then be created for each dimension and fact table in the data
warehouse. pygrametl provides many types of abstractions for dimensions and
fact tables, but in this example, we use the simplest ones. For more
information about the more advanced dimension and fact table classes, see
<a class="reference internal" href="../examples/dimensions.html#dimensions"><span class="std std-ref">Dimensions</span></a> and <a class="reference internal" href="../examples/facttables.html#facttables"><span class="std std-ref">Fact Tables</span></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># An instance of CachedDimension is created for each dimension in the data</span>
<span class="c1"># warehouse. CachedDimension uses a local cache to significantly reduce the</span>
<span class="c1"># number of requests issued to the RDBMS. CachedDimension should generally</span>
<span class="c1"># be used instead of Dimension unless the higher memory consumption causes</span>
<span class="c1"># problems. For each dimension, the name of the database table, the table&#39;s</span>
<span class="c1"># primary key, and the table&#39;s non-key columns (attributes) are given. In</span>
<span class="c1"># addition, for the location dimension, the subset of the attributes that</span>
<span class="c1"># should be used to lookup the primary key is given. As mentioned in the</span>
<span class="c1"># beginning of this guide, using named parameters is strongly encouraged</span>
<span class="n">book_dimension</span> <span class="o">=</span> <span class="n">CachedDimension</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;book&#39;</span><span class="p">,</span>
        <span class="n">key</span><span class="o">=</span><span class="s1">&#39;bookid&#39;</span><span class="p">,</span>
        <span class="n">attributes</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;book&#39;</span><span class="p">,</span> <span class="s1">&#39;genre&#39;</span><span class="p">])</span>

<span class="n">time_dimension</span> <span class="o">=</span> <span class="n">CachedDimension</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;time&#39;</span><span class="p">,</span>
        <span class="n">key</span><span class="o">=</span><span class="s1">&#39;timeid&#39;</span><span class="p">,</span>
        <span class="n">attributes</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;day&#39;</span><span class="p">,</span> <span class="s1">&#39;month&#39;</span><span class="p">,</span> <span class="s1">&#39;year&#39;</span><span class="p">])</span>

<span class="n">location_dimension</span> <span class="o">=</span> <span class="n">CachedDimension</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;location&#39;</span><span class="p">,</span>
        <span class="n">key</span><span class="o">=</span><span class="s1">&#39;locationid&#39;</span><span class="p">,</span>
        <span class="n">attributes</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;city&#39;</span><span class="p">,</span> <span class="s1">&#39;region&#39;</span><span class="p">],</span>
        <span class="n">lookupatts</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;city&#39;</span><span class="p">])</span>

<span class="c1"># A single instance of FactTable is created for the data warehouse&#39;s single</span>
<span class="c1"># fact table. It is created with the name of the table, a list of columns</span>
<span class="c1"># constituting the primary key of the fact table, and a list of measures</span>
<span class="n">fact_table</span> <span class="o">=</span> <span class="n">FactTable</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;facttable&#39;</span><span class="p">,</span>
        <span class="n">keyrefs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;bookid&#39;</span><span class="p">,</span> <span class="s1">&#39;locationid&#39;</span><span class="p">,</span> <span class="s1">&#39;timeid&#39;</span><span class="p">],</span>
        <span class="n">measures</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;sale&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>As the input dates are datetime objects and the time dimension consists of
multiple levels (day, month, and year), the datetime objects must be split into
their separate values. For this, a normal Python function is created and passed
each of the rows. As pygrametl is a Python package, data transformations can be
implemented using standard Python without any syntactic additions or
restrictions. This also means that Python’s many packages can be used as part
of an ETL flow.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># A normal Python function is used to split the date into its parts</span>
<span class="k">def</span> <span class="nf">split_date</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Splits a date represented by a datetime into its three parts&quot;&quot;&quot;</span>

    <span class="c1"># First the datetime object is extracted from the row dictionary</span>
    <span class="n">date</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span>

    <span class="c1"># Then each part is reassigned to the row dictionary. It can then be</span>
    <span class="c1"># accessed by the caller as the row is a reference to the dict object</span>
    <span class="n">row</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">date</span><span class="o">.</span><span class="n">year</span>
    <span class="n">row</span><span class="p">[</span><span class="s1">&#39;month&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">date</span><span class="o">.</span><span class="n">month</span>
    <span class="n">row</span><span class="p">[</span><span class="s1">&#39;day&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">date</span><span class="o">.</span><span class="n">day</span>
</pre></div>
</div>
<p>Finally, the data can be inserted into the data warehouse. All rows from the
CSV file are inserted into the location dimension first. This is necessary for
foreign keys to the location dimension to be computed while filling the fact
table. The other two dimensions are filled while inserting the facts as the
data needed is included in the sales records. To ensure that the data is
committed to the database and that the connection is closed correctly, the
methods <a class="reference internal" href="../api/pygrametl.html#pygrametl.ConnectionWrapper.commit" title="pygrametl.ConnectionWrapper.commit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">ConnectionWrapper.commit()</span></code></a> and <a class="reference internal" href="../api/pygrametl.html#pygrametl.ConnectionWrapper.close" title="pygrametl.ConnectionWrapper.close"><code class="xref py py-meth docutils literal notranslate"><span class="pre">ConnectionWrapper.close()</span></code></a>
are executed at the end.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># The Location dimension is filled with data from the CSV file as the file</span>
<span class="c1"># contains all the information required for both columns in the table. If</span>
<span class="c1"># the dimension was filled using data from the sales database, it would be</span>
<span class="c1"># necessary to update the region attribute with data from the CSV file</span>
<span class="c1"># later. To insert the rows the method CachedDimension.insert() is used</span>
<span class="p">[</span><span class="n">location_dimension</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">row</span><span class="p">)</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">region_source</span><span class="p">]</span>

<span class="c1"># The file handle to the CSV file can then be closed</span>
<span class="n">region_file_handle</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="c1"># All the information needed for the other dimensions are stored in the</span>
<span class="c1"># sales database. So with only a single iteration over the sales records</span>
<span class="c1"># the ETL flow can split the date and lookup the three dimension keys</span>
<span class="c1"># needed for the fact table. While retrieving the dimension keys, pygrametl</span>
<span class="c1"># can automatically update the dimensions with new data if ensure() is</span>
<span class="c1"># used. This method combines a lookup with an insertion so a new row is</span>
<span class="c1"># only inserted into the dimension or fact table if it does not yet exist</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">sale_source</span><span class="p">:</span>

    <span class="c1"># The date is split into its three parts</span>
    <span class="n">split_date</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>

    <span class="c1"># The row is updated with the correct primary keys for each dimension, and</span>
    <span class="c1"># any new data are inserted into each of the dimensions at the same time</span>
    <span class="n">row</span><span class="p">[</span><span class="s1">&#39;bookid&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">book_dimension</span><span class="o">.</span><span class="n">ensure</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
    <span class="n">row</span><span class="p">[</span><span class="s1">&#39;timeid&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">time_dimension</span><span class="o">.</span><span class="n">ensure</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>

    <span class="c1"># CachedDimension.ensure() is not used for the location dimension as it</span>
    <span class="c1"># has already been filled. Instead the method CachedDimension.lookup()</span>
    <span class="c1"># is used. CachedDimension.lookup() does not insert any data and</span>
    <span class="c1"># returns None if a row with the correct lookupatts is not available.</span>
    <span class="c1"># This makes error handling very simple to implement. In this case an</span>
    <span class="c1"># error is raised if a location is missing from the CSV file as</span>
    <span class="c1"># recovery is not possible</span>
    <span class="n">row</span><span class="p">[</span><span class="s1">&#39;locationid&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">location_dimension</span><span class="o">.</span><span class="n">lookup</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;locationid&#39;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;city was not present in the location dimension&quot;</span><span class="p">)</span>

    <span class="c1"># As the number of sales is already aggregated in the sales records, the</span>
    <span class="c1"># row can now be inserted into the data warehouse. If aggregation, or</span>
    <span class="c1"># other more advanced transformations are required, the full power of</span>
    <span class="c1"># Python is available as shown with the call to split_date()</span>
    <span class="n">fact_table</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>

<span class="c1"># After all the data have been inserted, the connection is ordered to</span>
<span class="c1"># commit and is then closed. This ensures that the data is committed to the</span>
<span class="c1"># database and that the resources used by the connection are released</span>
<span class="n">dw_conn_wrapper</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>
<span class="n">dw_conn_wrapper</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="c1"># Finally, the connection to the sales database is closed</span>
<span class="n">sale_conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>This small example shows how to quickly create a very simple ETL flow with
pygrametl. A combined version with fewer comments can be seen below. However,
since this is a very small and simple example, the batching and bulk loading
built into some of the more advanced dimension and fact table classes has not
been used. For larger ETL flows, these can be used to significantly increase
the throughput of an ETL flow. See <a class="reference internal" href="../examples/dimensions.html#dimensions"><span class="std std-ref">Dimensions</span></a> and <a class="reference internal" href="../examples/facttables.html#facttables"><span class="std std-ref">Fact Tables</span></a> for
more information. The simple parallel capabilities of pygrametl can also be
used to further increase the throughput of an ETL flow (see <a class="reference internal" href="../examples/parallel.html#parallel"><span class="std std-ref">Parallel</span></a>),
and the correctness of an ETL flow should also be checked using a set of
automated repeatable tests (see <a class="reference internal" href="../examples/testing.html#testing"><span class="std std-ref">Drawn Table Testing</span></a>).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">psycopg2</span>
<span class="kn">import</span> <span class="nn">sqlite3</span>
<span class="kn">import</span> <span class="nn">pygrametl</span>
<span class="kn">from</span> <span class="nn">pygrametl.datasources</span> <span class="kn">import</span> <span class="n">SQLSource</span><span class="p">,</span> <span class="n">CSVSource</span>
<span class="kn">from</span> <span class="nn">pygrametl.tables</span> <span class="kn">import</span> <span class="n">CachedDimension</span><span class="p">,</span> <span class="n">FactTable</span>

<span class="c1"># Opening of connections and creation of a ConnectionWrapper</span>
<span class="n">sale_conn</span> <span class="o">=</span> <span class="n">sqlite3</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="s2">&quot;sale.sqlite&quot;</span><span class="p">,</span>
        <span class="n">detect_types</span><span class="o">=</span><span class="n">sqlite3</span><span class="o">.</span><span class="n">PARSE_DECLTYPES</span><span class="p">)</span>

<span class="n">dw_string</span> <span class="o">=</span> <span class="s2">&quot;host=&#39;localhost&#39; dbname=&#39;dw&#39; user=&#39;dwuser&#39; password=&#39;dwpass&#39;&quot;</span>
<span class="n">dw_conn</span> <span class="o">=</span> <span class="n">psycopg2</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">dw_string</span><span class="p">)</span>
<span class="n">dw_conn_wrapper</span> <span class="o">=</span> <span class="n">pygrametl</span><span class="o">.</span><span class="n">ConnectionWrapper</span><span class="p">(</span><span class="n">connection</span><span class="o">=</span><span class="n">dw_conn</span><span class="p">)</span>

<span class="c1"># Creation of data sources for the sales database and the CSV file</span>
<span class="c1"># containing extra information about cities and regions in Denmark</span>
<span class="n">name_mapping</span> <span class="o">=</span> <span class="s1">&#39;book&#39;</span><span class="p">,</span> <span class="s1">&#39;genre&#39;</span><span class="p">,</span> <span class="s1">&#39;city&#39;</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="s1">&#39;sale&#39;</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;SELECT book, genre, store, date, sale FROM sale&quot;</span>
<span class="n">sale_source</span> <span class="o">=</span> <span class="n">SQLSource</span><span class="p">(</span><span class="n">connection</span><span class="o">=</span><span class="n">sale_conn</span><span class="p">,</span> <span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span>
        <span class="n">names</span><span class="o">=</span><span class="n">name_mapping</span><span class="p">)</span>

<span class="n">region_file_handle</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;region.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="mi">16384</span><span class="p">,</span> <span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>
<span class="n">region_source</span> <span class="o">=</span> <span class="n">CSVSource</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">region_file_handle</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>

<span class="c1"># Creation of dimension and fact table abstractions for use in the ETL flow</span>
<span class="n">book_dimension</span> <span class="o">=</span> <span class="n">CachedDimension</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;book&#39;</span><span class="p">,</span>
        <span class="n">key</span><span class="o">=</span><span class="s1">&#39;bookid&#39;</span><span class="p">,</span>
        <span class="n">attributes</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;book&#39;</span><span class="p">,</span> <span class="s1">&#39;genre&#39;</span><span class="p">])</span>

<span class="n">time_dimension</span> <span class="o">=</span> <span class="n">CachedDimension</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;time&#39;</span><span class="p">,</span>
        <span class="n">key</span><span class="o">=</span><span class="s1">&#39;timeid&#39;</span><span class="p">,</span>
        <span class="n">attributes</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;day&#39;</span><span class="p">,</span> <span class="s1">&#39;month&#39;</span><span class="p">,</span> <span class="s1">&#39;year&#39;</span><span class="p">])</span>

<span class="n">location_dimension</span> <span class="o">=</span> <span class="n">CachedDimension</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;location&#39;</span><span class="p">,</span>
        <span class="n">key</span><span class="o">=</span><span class="s1">&#39;locationid&#39;</span><span class="p">,</span>
        <span class="n">attributes</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;city&#39;</span><span class="p">,</span> <span class="s1">&#39;region&#39;</span><span class="p">],</span>
        <span class="n">lookupatts</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;city&#39;</span><span class="p">])</span>

<span class="n">fact_table</span> <span class="o">=</span> <span class="n">FactTable</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;facttable&#39;</span><span class="p">,</span>
        <span class="n">keyrefs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;bookid&#39;</span><span class="p">,</span> <span class="s1">&#39;locationid&#39;</span><span class="p">,</span> <span class="s1">&#39;timeid&#39;</span><span class="p">],</span>
        <span class="n">measures</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;sale&#39;</span><span class="p">])</span>

<span class="c1"># Python function needed to split the date into its three parts</span>
<span class="k">def</span> <span class="nf">split_date</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Splits a date represented by a datetime into its three parts&quot;&quot;&quot;</span>

    <span class="c1"># Splitting of the date into parts</span>
    <span class="n">date</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span>
    <span class="n">row</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">date</span><span class="o">.</span><span class="n">year</span>
    <span class="n">row</span><span class="p">[</span><span class="s1">&#39;month&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">date</span><span class="o">.</span><span class="n">month</span>
    <span class="n">row</span><span class="p">[</span><span class="s1">&#39;day&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">date</span><span class="o">.</span><span class="n">day</span>

<span class="c1"># The location dimension is loaded from the CSV file</span>
<span class="p">[</span><span class="n">location_dimension</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">row</span><span class="p">)</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">region_source</span><span class="p">]</span>

<span class="c1"># The file handle for the CSV file can then be closed</span>
<span class="n">region_file_handle</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="c1"># Each row in the sales database is iterated through and inserted</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">sale_source</span><span class="p">:</span>

    <span class="c1"># Each row is passed to the date split function for splitting</span>
    <span class="n">split_date</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>

    <span class="c1"># Lookups are performed to find the key in each dimension for the fact</span>
    <span class="c1"># and if the data is not there, it is inserted from the sales row</span>
    <span class="n">row</span><span class="p">[</span><span class="s1">&#39;bookid&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">book_dimension</span><span class="o">.</span><span class="n">ensure</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
    <span class="n">row</span><span class="p">[</span><span class="s1">&#39;timeid&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">time_dimension</span><span class="o">.</span><span class="n">ensure</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>

    <span class="c1"># The location dimension is pre-filled, so a missing row is an error</span>
    <span class="n">row</span><span class="p">[</span><span class="s1">&#39;locationid&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">location_dimension</span><span class="o">.</span><span class="n">lookup</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;locationid&#39;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;city was not present in the location dimension&quot;</span><span class="p">)</span>

    <span class="c1"># The row can then be inserted into the fact table</span>
    <span class="n">fact_table</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>

<span class="c1"># The data warehouse connection is then ordered to commit and close</span>
<span class="n">dw_conn_wrapper</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>
<span class="n">dw_conn_wrapper</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="c1"># Finally, the connection to the sales database is closed</span>
<span class="n">sale_conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">pygrametl</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="install.html">Install Guide</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Beginner Guide</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../examples/database.html">Database</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/datasources.html">Data Sources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/dimensions.html">Dimensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/facttables.html">Fact Tables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/bulkloading.html">Bulk Loading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/parallel.html">Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/jython.html">Jython</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/testing.html">Testing</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/pygrametl.html">pygrametl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/datasources.html">datasources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/tables.html">tables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/parallel.html">parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/jdbcconnectionwrapper.html">JDBCConnectionWrapper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/jythonmultiprocessing.html">jythonmultiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/aggregators.html">aggregators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/steps.html">steps</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/fifodict.html">FIFODict</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/drawntabletesting.html">drawntabletesting</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="install.html" title="previous chapter">Install Guide</a></li>
      <li>Next: <a href="../examples/database.html" title="next chapter">Database</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2009 - 2022, Aalborg University.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 5.3.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/quickstart/beginner.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>