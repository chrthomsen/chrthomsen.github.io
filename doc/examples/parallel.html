
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Parallel &#8212; pygrametl 2.7 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Jython" href="jython.html" />
    <link rel="prev" title="Bulk Loading" href="bulkloading.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="parallel">
<span id="id1"></span><h1>Parallel<a class="headerlink" href="#parallel" title="Permalink to this heading">¶</a></h1>
<p>pygrametl provides multiple abstractions to simplify the creation of parallel
ETL flow, to take advantage of modern multi-core and multi-processor systems.
Firstly, any <a class="reference internal" href="../api/datasources.html#module-pygrametl.datasources" title="pygrametl.datasources"><code class="xref py py-mod docutils literal notranslate"><span class="pre">datasources</span></code></a> can be read in a separate process using
<a class="reference internal" href="../api/datasources.html#pygrametl.datasources.ProcessSource" title="pygrametl.datasources.ProcessSource"><code class="xref py py-class docutils literal notranslate"><span class="pre">ProcessSource</span></code></a>. Further parallelism can be archived by decoupling
tables from the main process and allowing these decoupled tables to communicate
with each other without interrupting the main process. Tables can also be
partitioned so operations on large tables can be performed by multiple
processes. Both decoupled tables and partitioning tables can be found in the
<a class="reference internal" href="../api/tables.html#module-pygrametl.tables" title="pygrametl.tables"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tables</span></code></a> module. To support database connections from multiple decoupled
tables any <a class="reference internal" href="../api/pygrametl.html#pygrametl.ConnectionWrapper" title="pygrametl.ConnectionWrapper"><code class="xref py py-class docutils literal notranslate"><span class="pre">ConnectionWrapper</span></code></a> and <a class="reference internal" href="../api/jdbcconnectionwrapper.html#pygrametl.JDBCConnectionWrapper.JDBCConnectionWrapper" title="pygrametl.JDBCConnectionWrapper.JDBCConnectionWrapper"><code class="xref py py-class docutils literal notranslate"><span class="pre">JDBCConnectionWrapper</span></code></a> must
be wrapped by the function <a class="reference internal" href="../api/parallel.html#pygrametl.parallel.shareconnectionwrapper" title="pygrametl.parallel.shareconnectionwrapper"><code class="xref py py-func docutils literal notranslate"><span class="pre">shareconnectionwrapper()</span></code></a> before being used by
multiple decoupled tables.</p>
<p>pygrametl also provides abstractions for running functions in parallel. The
decorator <a class="reference internal" href="../api/parallel.html#pygrametl.parallel.splitpoint" title="pygrametl.parallel.splitpoint"><code class="xref py py-func docutils literal notranslate"><span class="pre">splitpoint()</span></code></a> can be used to annotate functions that should run
in separate processes. This supplements the decoupled tables, as many
transformations are done in a set of functions before they are inserted into a
database table. Splitpoints can be synchronized using the function
<a class="reference internal" href="../api/parallel.html#pygrametl.parallel.endsplits" title="pygrametl.parallel.endsplits"><code class="xref py py-func docutils literal notranslate"><span class="pre">endsplits()</span></code></a>. The function <a class="reference internal" href="../api/parallel.html#pygrametl.parallel.createflow" title="pygrametl.parallel.createflow"><code class="xref py py-func docutils literal notranslate"><span class="pre">createflow()</span></code></a> can be used to create a
sequence of functions that run in separate processes. In a flow a row is first
given to the first function, then the second, and so forth. This also means the
passed row must be modified as the functions return values are ignored.</p>
<p>Due to CPython’s <a class="reference external" href="https://wiki.python.org/moin/GlobalInterpreterLock">GIL</a>,
Jython should be used to run ETL flows that use pygrametl parallel constructs.
This is because Jython allows threads to be used for parallel processing, while
it is necessary to use processes in CPython. Thus the term process is used to
denote a process or a thread, depending on the Python implementation in
question. For more information on using pygrametl on Jython, see <a class="reference internal" href="jython.html#jython"><span class="std std-ref">Jython</span></a>.</p>
<section id="processsource">
<h2>ProcessSource<a class="headerlink" href="#processsource" title="Permalink to this heading">¶</a></h2>
<p><a class="reference internal" href="../api/datasources.html#pygrametl.datasources.ProcessSource" title="pygrametl.datasources.ProcessSource"><code class="xref py py-class docutils literal notranslate"><span class="pre">ProcessSource</span></code></a> is a data source that allows other data sources to be
iterated through in a separate process. A data source in pygrametl is a set of
abstraction that provides access to multiple types of data through a normal
Python iterator. For more information about data sources see <a class="reference internal" href="datasources.html#datasources"><span class="std std-ref">Data Sources</span></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pygrametl.tables</span> <span class="kn">import</span> <span class="n">FactTable</span><span class="p">,</span> <span class="n">CachedDimension</span>
<span class="kn">from</span> <span class="nn">pygrametl.datasources</span> <span class="kn">import</span> <span class="n">CSVSource</span><span class="p">,</span> <span class="n">ProcessSource</span><span class="p">,</span> \
        <span class="n">TransformingSource</span>
<span class="kn">from</span> <span class="nn">pygrametl.JDBCConnectionWrapper</span> <span class="kn">import</span> <span class="n">JDBCConnectionWrapper</span>

<span class="c1"># JDBC and Jython are used as threads usually provide better performance</span>
<span class="kn">import</span> <span class="nn">java.sql.DriverManager</span>
<span class="n">jconn</span> <span class="o">=</span> <span class="n">java</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">DriverManager</span><span class="o">.</span><span class="n">getConnection</span><span class="p">(</span>
    <span class="s2">&quot;jdbc:postgresql://localhost/dw?user=dwuser&amp;password=dwpass&quot;</span><span class="p">)</span>
<span class="n">conn</span> <span class="o">=</span> <span class="n">JDBCConnectionWrapper</span><span class="p">(</span><span class="n">jdbcconn</span><span class="o">=</span><span class="n">jconn</span><span class="p">)</span>

<span class="n">factTable</span> <span class="o">=</span> <span class="n">FactTable</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;facttable&#39;</span><span class="p">,</span>
    <span class="n">measures</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;sale&#39;</span><span class="p">],</span>
    <span class="n">keyrefs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;storeid&#39;</span><span class="p">,</span> <span class="s1">&#39;productid&#39;</span><span class="p">,</span> <span class="s1">&#39;dateid&#39;</span><span class="p">])</span>

<span class="n">productTable</span> <span class="o">=</span> <span class="n">CachedDimension</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;product&#39;</span><span class="p">,</span>
        <span class="n">key</span><span class="o">=</span><span class="s1">&#39;productid&#39;</span><span class="p">,</span>
        <span class="n">attributes</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;price&#39;</span><span class="p">],</span>
        <span class="n">lookupatts</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">])</span>


<span class="c1"># A set of computational expensive functions are needed to transform the</span>
<span class="c1"># facts before they can be inserted into the fact table. Each function must</span>
<span class="c1"># be defined as func(row) so a TransformationSource can combine them before</span>
<span class="c1"># they are passed to ProcessSource and run in another thread</span>
<span class="k">def</span> <span class="nf">convertReals</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="c1"># Converting a string encoding of a float to an integer must be done in</span>
    <span class="c1"># two steps, first it must be converted to a float and then to an integer</span>
    <span class="n">row</span><span class="p">[</span><span class="s1">&#39;sale&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;sale&#39;</span><span class="p">]))</span>


<span class="k">def</span> <span class="nf">trimProductname</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="n">row</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>


<span class="c1"># In the transformation we use three data sources to retrieve rows from</span>
<span class="c1"># sales.csv, first CSVSource to read the csv file, then</span>
<span class="c1"># TransformationSource to transform the rows, and lastly ProcessSource to</span>
<span class="c1"># do both the reading and transformation in another thread</span>
<span class="n">sales</span> <span class="o">=</span> <span class="n">CSVSource</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="nb">open</span><span class="p">(</span><span class="s1">&#39;sales.csv&#39;</span><span class="p">),</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
<span class="n">transSales</span> <span class="o">=</span> <span class="n">TransformingSource</span><span class="p">(</span><span class="n">sales</span><span class="p">,</span> <span class="n">convertReals</span><span class="p">,</span> <span class="n">trimProductname</span><span class="p">)</span>
<span class="n">salesProcess</span> <span class="o">=</span> <span class="n">ProcessSource</span><span class="p">(</span><span class="n">transSales</span><span class="p">)</span>

<span class="c1"># While the list of sales are being read and transformed by the spawned</span>
<span class="c1"># thread, the main thread is occupied with pre-loading the product dimension</span>
<span class="c1"># with data from product.csv</span>
<span class="n">products</span> <span class="o">=</span> <span class="n">CSVSource</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="nb">open</span><span class="p">(</span><span class="s1">&#39;product.csv&#39;</span><span class="p">),</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">products</span><span class="p">:</span>
    <span class="n">productTable</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>

<span class="c1"># After the ProcessSource have read rows from the data source provided, they</span>
<span class="c1"># can be accessed through ProcessSource iterator like any other data source</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">salesProcess</span><span class="p">:</span>
    <span class="n">row</span><span class="p">[</span><span class="s1">&#39;productid&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">productTable</span><span class="o">.</span><span class="n">lookup</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
    <span class="n">factTable</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
<span class="n">conn</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>
<span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>In the above example, we use a <a class="reference internal" href="../api/datasources.html#pygrametl.datasources.ProcessSource" title="pygrametl.datasources.ProcessSource"><code class="xref py py-class docutils literal notranslate"><span class="pre">ProcessSource</span></code></a> to transform a set of rows
from sales.csv while we fill the product dimension with data. As the use of a
<a class="reference internal" href="../api/datasources.html#pygrametl.datasources.ProcessSource" title="pygrametl.datasources.ProcessSource"><code class="xref py py-class docutils literal notranslate"><span class="pre">ProcessSource</span></code></a> adds additional overhead to the iterator, seeing as rows
must be transferred in batches from another process, other computations should
be performed in between the creation and use of the data source to allow for
data to be read, transformed, and transferred.</p>
</section>
<section id="decoupled-tables">
<h2>Decoupled Tables<a class="headerlink" href="#decoupled-tables" title="Permalink to this heading">¶</a></h2>
<p>A decoupled table in pygrametl is a proxy for an instance of another table class
defined in the <a class="reference internal" href="../api/tables.html#module-pygrametl.tables" title="pygrametl.tables"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tables</span></code></a> module. Currently, two different classes exist for
decoupled tables, <a class="reference internal" href="../api/tables.html#pygrametl.tables.DecoupledDimension" title="pygrametl.tables.DecoupledDimension"><code class="xref py py-class docutils literal notranslate"><span class="pre">DecoupledDimension</span></code></a> and <a class="reference internal" href="../api/tables.html#pygrametl.tables.DecoupledFactTable" title="pygrametl.tables.DecoupledFactTable"><code class="xref py py-class docutils literal notranslate"><span class="pre">DecoupledFactTable</span></code></a>.
The two classes behave nearly identically with one implementing the interface of
a dimension and the other the interface of a fact table. When a method is called
on one of the two classes, a message is sent to the actual table object, and if
the method has a return value an instance of the class <code class="xref py py-class docutils literal notranslate"><span class="pre">FutureResult</span></code> is
returned. This instance is a handle to the actual result when it becomes
available. To get the actual result, the instance can be given directly to a
method accepting a row which would force the method to block until a value is
ready, or the entire decoupled can be consumed by another decoupled table. When
a decoupled table is consumed by another decoupled table, the values are
extracted from an instance of <code class="xref py py-class docutils literal notranslate"><span class="pre">FutureResult</span></code> by the table that needs it
without blocking the caller of methods on that table. It should however be noted
that any rows passed to an instance of <a class="reference internal" href="../api/tables.html#pygrametl.tables.DecoupledFactTable" title="pygrametl.tables.DecoupledFactTable"><code class="xref py py-class docutils literal notranslate"><span class="pre">DecoupledFactTable</span></code></a> or
<a class="reference internal" href="../api/tables.html#pygrametl.tables.DecoupledDimension" title="pygrametl.tables.DecoupledDimension"><code class="xref py py-class docutils literal notranslate"><span class="pre">DecoupledDimension</span></code></a> should only contain the attributes directly needed
by the table, as having additional key/value pairs in the <code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code> can
make pygrametl insert the row before the actual values are ready, leading to
instances of the class <code class="xref py py-class docutils literal notranslate"><span class="pre">FutureResult</span></code> being incorrectly passed to the
database instead.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pygrametl.datasources</span> <span class="kn">import</span> <span class="n">CSVSource</span>
<span class="kn">from</span> <span class="nn">pygrametl.tables</span> <span class="kn">import</span> <span class="n">FactTable</span><span class="p">,</span> <span class="n">CachedDimension</span><span class="p">,</span>\
     <span class="n">DecoupledDimension</span><span class="p">,</span> <span class="n">DecoupledFactTable</span>
<span class="kn">from</span> <span class="nn">pygrametl.JDBCConnectionWrapper</span> <span class="kn">import</span> <span class="n">JDBCConnectionWrapper</span>
<span class="kn">from</span> <span class="nn">pygrametl.parallel</span> <span class="kn">import</span> <span class="n">shareconnectionwrapper</span>

<span class="c1"># The data is read from a csv file</span>
<span class="n">inputdata</span> <span class="o">=</span> <span class="n">CSVSource</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="nb">open</span><span class="p">(</span><span class="s1">&#39;sales.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">),</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>

<span class="c1"># JDBC and Jython are used as threads usually provide better performance</span>
<span class="kn">import</span> <span class="nn">java.sql.DriverManager</span>
<span class="n">jconn</span> <span class="o">=</span> <span class="n">java</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">DriverManager</span><span class="o">.</span><span class="n">getConnection</span><span class="p">(</span>
    <span class="s2">&quot;jdbc:postgresql://localhost/dw?user=dwuser&amp;password=dwpass&quot;</span><span class="p">)</span>

<span class="c1"># The connection wrapper is itself wrapped in a SharedConnectionClient,</span>
<span class="c1"># so it can be shared by multiple decoupled tables in a safe manner</span>
<span class="n">conn</span> <span class="o">=</span> <span class="n">JDBCConnectionWrapper</span><span class="p">(</span><span class="n">jdbcconn</span><span class="o">=</span><span class="n">jconn</span><span class="p">)</span>
<span class="n">shrdconn</span> <span class="o">=</span> <span class="n">shareconnectionwrapper</span><span class="p">(</span><span class="n">targetconnection</span><span class="o">=</span><span class="n">conn</span><span class="p">)</span>

<span class="c1"># The product dimension is decoupled and runs in a separate thread allowing</span>
<span class="c1"># it to be accessed by other decoupled tables without using the main thread</span>
<span class="n">productDimension</span> <span class="o">=</span> <span class="n">DecoupledDimension</span><span class="p">(</span>
    <span class="n">CachedDimension</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;product&#39;</span><span class="p">,</span>
        <span class="n">key</span><span class="o">=</span><span class="s1">&#39;productid&#39;</span><span class="p">,</span>
        <span class="n">attributes</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;price&#39;</span><span class="p">],</span>
        <span class="n">lookupatts</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">],</span>
        <span class="c1"># The SharedConnectionWrapperClient must be copied for each</span>
        <span class="c1"># decoupled table that use it correct interaction with the database</span>
        <span class="n">targetconnection</span><span class="o">=</span><span class="n">shrdconn</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
        <span class="n">prefill</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">)</span>

<span class="c1"># The fact table is also decoupled in order to consume the values returned</span>
<span class="c1"># from the methods called on the product dimension without blocking the main</span>
<span class="c1"># thread while waiting for the database. Thus allowing the main thread to</span>
<span class="c1"># perform other operations needed before a full fact is ready</span>
<span class="n">factTable</span> <span class="o">=</span> <span class="n">DecoupledFactTable</span><span class="p">(</span>
    <span class="n">FactTable</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;facttable&#39;</span><span class="p">,</span>
        <span class="n">measures</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;sale&#39;</span><span class="p">],</span>
        <span class="n">keyrefs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;storeid&#39;</span><span class="p">,</span> <span class="s1">&#39;productid&#39;</span><span class="p">,</span> <span class="s1">&#39;dateid&#39;</span><span class="p">],</span>
        <span class="n">targetconnection</span><span class="o">=</span><span class="n">shrdconn</span><span class="o">.</span><span class="n">copy</span><span class="p">()),</span>
    <span class="n">returnvalues</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">consumes</span><span class="o">=</span><span class="p">[</span><span class="n">productDimension</span><span class="p">]</span>
    <span class="p">)</span>

<span class="c1"># Inserting facts into the database can be done in the same manner as in a</span>
<span class="c1"># sequential ETL flow, extraction of data from the product dimension is</span>
<span class="c1"># done automatically by pygrametl</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">inputdata</span><span class="p">:</span>
    <span class="c1"># A new row is created for each fact, as having values not present in a</span>
    <span class="c1"># decoupled table that consumes another dimension, can make pygrametl</span>
    <span class="c1"># miscalculate when the actual results are ready, making the framework</span>
    <span class="c1"># pass a FutureResult to the database which usually raises an error</span>
    <span class="n">fact</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">fact</span><span class="p">[</span><span class="s1">&#39;storeid&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;storeid&#39;</span><span class="p">]</span>
    <span class="n">fact</span><span class="p">[</span><span class="s1">&#39;productid&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">productDimension</span><span class="o">.</span><span class="n">ensure</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
    <span class="n">fact</span><span class="p">[</span><span class="s1">&#39;dateid&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;dateid&#39;</span><span class="p">]</span>
    <span class="n">fact</span><span class="p">[</span><span class="s1">&#39;sale&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;sale&#39;</span><span class="p">]</span>
    <span class="c1"># Other CPU intensive transformations should be performed to take</span>
    <span class="c1"># advantage of the decoupled dimensions automatically exchanging data</span>
    <span class="n">factTable</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">fact</span><span class="p">)</span>
<span class="n">shrdconn</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>
<span class="n">shrdconn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>The above example shows a very simple use of decoupled tables in pygrametl, for
real-world application, tuning of queues and buffers should be done to match the
underlying hardware to maximize the performance of the parallel ETL flow.
Although the example uses an instance of <a class="reference internal" href="../api/tables.html#pygrametl.tables.Dimension" title="pygrametl.tables.Dimension"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dimension</span></code></a> and
<a class="reference internal" href="../api/tables.html#pygrametl.tables.FactTable" title="pygrametl.tables.FactTable"><code class="xref py py-class docutils literal notranslate"><span class="pre">FactTable</span></code></a> for simplicity, it is supported for all types of dimensions
and fact tables, except <a class="reference internal" href="../api/tables.html#pygrametl.tables.SubprocessFactTable" title="pygrametl.tables.SubprocessFactTable"><code class="xref py py-class docutils literal notranslate"><span class="pre">SubprocessFactTable</span></code></a> on CPython as it already
runs in its own process. Decoupling of tables requiring a large amount of
processing when their methods are called, like a <a class="reference internal" href="../api/tables.html#pygrametl.tables.SnowflakedDimension" title="pygrametl.tables.SnowflakedDimension"><code class="xref py py-class docutils literal notranslate"><span class="pre">SnowflakedDimension</span></code></a>,
can help increase performance due to not blocking the main process while waiting
on the database performing the joins.</p>
<p>If any user-defined function needs to access the database and be synchronized
with the decoupled tables, it must be passed to <a class="reference internal" href="../api/parallel.html#pygrametl.parallel.shareconnectionwrapper" title="pygrametl.parallel.shareconnectionwrapper"><code class="xref py py-func docutils literal notranslate"><span class="pre">shareconnectionwrapper()</span></code></a>.
An example of such a function is the bulk loader used for pygrametl’s
<a class="reference internal" href="../api/tables.html#pygrametl.tables.BulkFactTable" title="pygrametl.tables.BulkFactTable"><code class="xref py py-class docutils literal notranslate"><span class="pre">BulkFactTable</span></code></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pygrametl.JDBCConnectionWrapper</span> <span class="kn">import</span> <span class="n">JDBCConnectionWrapper</span>
<span class="kn">from</span> <span class="nn">pygrametl.parallel</span> <span class="kn">import</span> <span class="n">shareconnectionwrapper</span>

<span class="c1"># JDBC and Jython is used as threads usually provides better performance</span>
<span class="kn">import</span> <span class="nn">java.sql.DriverManager</span>
<span class="n">jconn</span> <span class="o">=</span> <span class="n">java</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">DriverManager</span><span class="o">.</span><span class="n">getConnection</span><span class="p">(</span>
    <span class="s2">&quot;jdbc:postgresql://localhost/dw?user=dwuser&amp;password=dwpass&quot;</span><span class="p">)</span>


<span class="c1"># A user-defined function that can bulk load data into PostgreSQL over JDBC</span>
<span class="k">def</span> <span class="nf">bulkloader</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">attributes</span><span class="p">,</span> <span class="n">fieldsep</span><span class="p">,</span> <span class="n">rowsep</span><span class="p">,</span> <span class="n">nullval</span><span class="p">,</span> <span class="n">filehandle</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">jconn</span>
    <span class="n">copymgr</span> <span class="o">=</span> <span class="n">jconn</span><span class="o">.</span><span class="n">getCopyAPI</span><span class="p">()</span>
    <span class="n">sql</span> <span class="o">=</span> <span class="s2">&quot;COPY </span><span class="si">%s</span><span class="s2">(</span><span class="si">%s</span><span class="s2">) FROM STDIN WITH DELIMITER &#39;</span><span class="si">%s</span><span class="s2">&#39;&quot;</span> <span class="o">%</span> \
          <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">attributes</span><span class="p">),</span> <span class="n">fieldsep</span><span class="p">)</span>
    <span class="n">copymgr</span><span class="o">.</span><span class="n">copyIn</span><span class="p">(</span><span class="n">sql</span><span class="p">,</span> <span class="n">filehandle</span><span class="p">)</span>


<span class="c1"># The connection wrapper is itself wrapped in a SharedConnectionClient so it</span>
<span class="c1"># can be shared by multiple decoupled tables in a safe manner. The function</span>
<span class="c1"># bulkloader is given to shareconnectionwrapper so the shared connection</span>
<span class="c1"># wrapper can ensure that the bulk loading function is synchronized with</span>
<span class="c1"># the decoupled tables using the shared connection wrapper</span>
<span class="n">conn</span> <span class="o">=</span> <span class="n">JDBCConnectionWrapper</span><span class="p">(</span><span class="n">jdbcconn</span><span class="o">=</span><span class="n">jconn</span><span class="p">)</span>
<span class="n">scw</span> <span class="o">=</span> <span class="n">shareconnectionwrapper</span><span class="p">(</span><span class="n">targetconnection</span><span class="o">=</span><span class="n">conn</span><span class="p">,</span> <span class="n">userfuncs</span><span class="o">=</span><span class="p">[</span><span class="n">bulkloader</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section id="partitioning-tables">
<h2>Partitioning Tables<a class="headerlink" href="#partitioning-tables" title="Permalink to this heading">¶</a></h2>
<p>If a particular dimension or fact table requires more processing than the other
tables, it can be beneficial to partition it into multiple partitions. Thus
allowing operations to be conducted on one table in parallel to reduce the time
needed to process that particular table. pygrametl supports partitioning of
tables through multiple features. Firstly, the classes
<a class="reference internal" href="../api/tables.html#pygrametl.tables.DimensionPartitioner" title="pygrametl.tables.DimensionPartitioner"><code class="xref py py-class docutils literal notranslate"><span class="pre">DimensionPartitioner</span></code></a> and <a class="reference internal" href="../api/tables.html#pygrametl.tables.FactTablePartitioner" title="pygrametl.tables.FactTablePartitioner"><code class="xref py py-class docutils literal notranslate"><span class="pre">FactTablePartitioner</span></code></a> automates the
partitioning of rows for multiple decoupled dimensions or fact tables. How to do
the partitioning is determined by a partitioning function with the signature
<code class="xref py py-func docutils literal notranslate"><span class="pre">func(dict)()</span></code>. If no function is passed, then a default partitioning
function is used as documented in the API. Secondly, to ensure that unique
surrogate keys are assigned to all rows in a partitioned table, a shared
sequence factory can be created using the function
<a class="reference internal" href="../api/parallel.html#pygrametl.parallel.getsharedsequencefactory" title="pygrametl.parallel.getsharedsequencefactory"><code class="xref py py-func docutils literal notranslate"><span class="pre">getsharedsequencefactory()</span></code></a>. Each parallel process is then given a unique
set of numbers to use as surrogate keys, ensuring that all surrogate keys are
unique despite being assigned by separate processes.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pygrametl.datasources</span> <span class="kn">import</span> <span class="n">CSVSource</span>
<span class="kn">from</span> <span class="nn">pygrametl.tables</span> <span class="kn">import</span> <span class="n">FactTable</span><span class="p">,</span> <span class="n">CachedDimension</span><span class="p">,</span> \
    <span class="n">DecoupledDimension</span><span class="p">,</span> <span class="n">DecoupledFactTable</span><span class="p">,</span> <span class="n">DimensionPartitioner</span>
<span class="kn">from</span> <span class="nn">pygrametl.parallel</span> <span class="kn">import</span> <span class="n">shareconnectionwrapper</span><span class="p">,</span> \
    <span class="n">getsharedsequencefactory</span>
<span class="kn">from</span> <span class="nn">pygrametl.JDBCConnectionWrapper</span> <span class="kn">import</span> <span class="n">JDBCConnectionWrapper</span>

<span class="n">sales</span> <span class="o">=</span> <span class="n">CSVSource</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="nb">open</span><span class="p">(</span><span class="s1">&#39;sales.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">),</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>

<span class="c1"># JDBC and Jython are used as threads usually provide better performance</span>
<span class="kn">import</span> <span class="nn">java.sql.DriverManager</span>
<span class="n">jconn</span> <span class="o">=</span> <span class="n">java</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">DriverManager</span><span class="o">.</span><span class="n">getConnection</span><span class="p">(</span>
    <span class="s2">&quot;jdbc:postgresql://localhost/dw?user=dwuser&amp;password=dwpass&quot;</span><span class="p">)</span>

<span class="c1"># The connection wrapper is itself wrapped in a SharedConnectionClient,</span>
<span class="c1"># so it can be shared by multiple decoupled tables in a safe manner</span>
<span class="n">conn</span> <span class="o">=</span> <span class="n">JDBCConnectionWrapper</span><span class="p">(</span><span class="n">jdbcconn</span><span class="o">=</span><span class="n">jconn</span><span class="p">)</span>
<span class="n">shrdconn</span> <span class="o">=</span> <span class="n">shareconnectionwrapper</span><span class="p">(</span><span class="n">targetconnection</span><span class="o">=</span><span class="n">conn</span><span class="p">)</span>

<span class="c1"># A sharedsequencefactory is created which provides values starting at zero.</span>
<span class="c1"># It gives each table a sequence of numbers to use as surrogate keys. The</span>
<span class="c1"># size of the sequence can be increased through a second argument if the</span>
<span class="c1"># sharedsequencefactory becomes a bottleneck in the ETL flow</span>
<span class="n">idfactory</span> <span class="o">=</span> <span class="n">getsharedsequencefactory</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># The product dimension must use the sharedsequencefactory to ensure that</span>
<span class="c1"># the two processes do not assign overlapping surrogate key to the rows</span>
<span class="n">productDimensionOne</span> <span class="o">=</span> <span class="n">DecoupledDimension</span><span class="p">(</span>
    <span class="n">CachedDimension</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;product&#39;</span><span class="p">,</span>
        <span class="n">key</span><span class="o">=</span><span class="s1">&#39;productid&#39;</span><span class="p">,</span>
        <span class="n">attributes</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;price&#39;</span><span class="p">],</span>
        <span class="n">lookupatts</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">],</span>
        <span class="n">idfinder</span><span class="o">=</span><span class="n">idfactory</span><span class="p">(),</span>
        <span class="n">targetconnection</span><span class="o">=</span><span class="n">shrdconn</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
        <span class="n">prefill</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">)</span>

<span class="n">productDimensionTwo</span> <span class="o">=</span> <span class="n">DecoupledDimension</span><span class="p">(</span>
    <span class="n">CachedDimension</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;product&#39;</span><span class="p">,</span>
        <span class="n">key</span><span class="o">=</span><span class="s1">&#39;productid&#39;</span><span class="p">,</span>
        <span class="n">attributes</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;price&#39;</span><span class="p">],</span>
        <span class="n">lookupatts</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">],</span>
        <span class="n">idfinder</span><span class="o">=</span><span class="n">idfactory</span><span class="p">(),</span>
        <span class="n">targetconnection</span><span class="o">=</span><span class="n">shrdconn</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
        <span class="n">prefill</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">)</span>

<span class="c1"># The partitioning of data is automated by the DimensionPartitioner using</span>
<span class="c1"># a hash on the name of product. A FactTablePartitioner is also provided</span>
<span class="n">productDimension</span> <span class="o">=</span> <span class="n">DimensionPartitioner</span><span class="p">(</span>
    <span class="n">parts</span><span class="o">=</span><span class="p">[</span><span class="n">productDimensionOne</span><span class="p">,</span> <span class="n">productDimensionTwo</span><span class="p">],</span>
    <span class="n">partitioner</span><span class="o">=</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="nb">hash</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]))</span>

<span class="c1"># Only partitioned tables needs to use the sharedsequencefactory, normal tables</span>
<span class="c1"># can without any problems use the default self-incrementing surrogate key</span>
<span class="n">factTable</span> <span class="o">=</span> <span class="n">DecoupledFactTable</span><span class="p">(</span>
        <span class="n">FactTable</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s1">&#39;facttable&#39;</span><span class="p">,</span>
            <span class="n">measures</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;sale&#39;</span><span class="p">],</span>
            <span class="n">keyrefs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;storeid&#39;</span><span class="p">,</span> <span class="s1">&#39;productid&#39;</span><span class="p">,</span> <span class="s1">&#39;dateid&#39;</span><span class="p">],</span>
            <span class="n">targetconnection</span><span class="o">=</span><span class="n">shrdconn</span><span class="o">.</span><span class="n">copy</span><span class="p">()),</span>
        <span class="n">returnvalues</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="c1"># When consuming a partitioned dimension each part should be</span>
        <span class="c1"># consumed separately, a simple way to do so is using the parts</span>
        <span class="c1"># method which returns all parts managed by the partitioner</span>
        <span class="n">consumes</span><span class="o">=</span><span class="n">productDimension</span><span class="o">.</span><span class="n">parts</span>
        <span class="p">)</span>

<span class="c1"># A partitioned table can be used in the same way as any other pygrametl</span>
<span class="c1"># table since the framework takes care of the partitioning behind the scenes</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">sales</span><span class="p">:</span>
    <span class="c1"># A new row is created for each fact, as having values not present in a</span>
    <span class="c1"># decoupled table that consumes another dimension, can make pygrametl</span>
    <span class="c1"># miscalculate when the actual results are ready, making the framework</span>
    <span class="c1"># pass a FutureResult to the database which usually raises an error</span>
    <span class="n">fact</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">fact</span><span class="p">[</span><span class="s1">&#39;storeid&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;storeid&#39;</span><span class="p">]</span>
    <span class="n">fact</span><span class="p">[</span><span class="s1">&#39;dateid&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;dateid&#39;</span><span class="p">]</span>
    <span class="n">fact</span><span class="p">[</span><span class="s1">&#39;productid&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">productDimension</span><span class="o">.</span><span class="n">ensure</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
    <span class="n">fact</span><span class="p">[</span><span class="s1">&#39;sale&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;sale&#39;</span><span class="p">]</span>
    <span class="c1"># Other CPU intensive transformations should be performed to take</span>
    <span class="c1"># advantage of the decoupled dimensions automatically exchanging data</span>
    <span class="n">factTable</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">fact</span><span class="p">)</span>
<span class="n">shrdconn</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>
<span class="n">shrdconn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>The above example shows how to partition the data of the product dimension to
multiple decoupled tables. This allows operations on the dimension to be
performed by two different processes. The rows are partitioned using hash
partitioning on the attribute <code class="xref py py-attr docutils literal notranslate"><span class="pre">name</span></code>. A shared sequence factory is used to
provide surrogate keys for the product dimension, as using a self-incrementing
key would assign the same value to multiple rows. This is not needed for the
fact table as only one table handles all operations on the fact table in the
database, so a simple self-incrementing key is fine.</p>
</section>
<section id="splitpoints">
<h2>Splitpoints<a class="headerlink" href="#splitpoints" title="Permalink to this heading">¶</a></h2>
<p>As CPU intensive operations are often performed in user-defined functions, the
decorator <a class="reference internal" href="../api/parallel.html#pygrametl.parallel.splitpoint" title="pygrametl.parallel.splitpoint"><code class="xref py py-func docutils literal notranslate"><span class="pre">splitpoint()</span></code></a> is provided. This decorator functions in much the
same way as decoupled classes do for tables, as a number of processes are
spawned to run the function. The number of processes to spawn can be passed to
the decorator, allowing more processes to be created for functions with a longer
run time. The first time a function with a decorator is called, a process is
created to handle the call. This is done until the number of created processes
matches the argument given to the decorator. Then, if a process is not available,
the call and its arguments are added to a <code class="xref py py-class docutils literal notranslate"><span class="pre">queue</span></code> shared by the process
created for the splitpoint. If a split function calls another function that
requires synchronization it can be annotated with a new splitpoint with one as
the argument, specifying that only one process is allowed to call this function
at a time. To ensure all annotated functions are finished, the function
<a class="reference internal" href="../api/parallel.html#pygrametl.parallel.endsplits" title="pygrametl.parallel.endsplits"><code class="xref py py-func docutils literal notranslate"><span class="pre">endsplits()</span></code></a> must be called, which joins all processes created by split
points up to that point.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pygrametl.tables</span> <span class="kn">import</span> <span class="n">FactTable</span>
<span class="kn">from</span> <span class="nn">pygrametl.datasources</span> <span class="kn">import</span> <span class="n">CSVSource</span>
<span class="kn">from</span> <span class="nn">pygrametl.parallel</span> <span class="kn">import</span> <span class="n">splitpoint</span><span class="p">,</span> <span class="n">endsplits</span>
<span class="kn">from</span> <span class="nn">pygrametl.JDBCConnectionWrapper</span> <span class="kn">import</span> <span class="n">JDBCConnectionWrapper</span>

<span class="n">sales</span> <span class="o">=</span> <span class="n">CSVSource</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="nb">open</span><span class="p">(</span><span class="s1">&#39;sales.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">),</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>

<span class="c1"># JDBC and Jython are used as threads usually provide better performance</span>
<span class="kn">import</span> <span class="nn">java.sql.DriverManager</span>
<span class="n">jconn</span> <span class="o">=</span> <span class="n">java</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">DriverManager</span><span class="o">.</span><span class="n">getConnection</span><span class="p">(</span>
    <span class="s2">&quot;jdbc:postgresql://localhost/dw?user=dwuser&amp;password=dwpass&quot;</span><span class="p">)</span>

<span class="n">conn</span> <span class="o">=</span> <span class="n">JDBCConnectionWrapper</span><span class="p">(</span><span class="n">jdbcconn</span><span class="o">=</span><span class="n">jconn</span><span class="p">)</span>

<span class="n">factTable</span> <span class="o">=</span> <span class="n">FactTable</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;facttable&#39;</span><span class="p">,</span>
    <span class="n">measures</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;sale&#39;</span><span class="p">],</span>
    <span class="n">keyrefs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;storeid&#39;</span><span class="p">,</span> <span class="s1">&#39;productid&#39;</span><span class="p">,</span> <span class="s1">&#39;dateid&#39;</span><span class="p">]</span>
    <span class="p">)</span>


<span class="c1"># Five threads are created to run this function, so five rows can be</span>
<span class="c1"># transformed at the same time. If no threads are available, the row</span>
<span class="c1"># is added to a queue and transformed when a thread becomes idle</span>
<span class="nd">@splitpoint</span><span class="p">(</span><span class="n">instances</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">performExpensiveTransformations</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="c1"># Do some (expensive) transformations...</span>

    <span class="c1"># As multiple threads perform the operation inside this function. a second</span>
    <span class="c1"># function must be created to synchronize inserting rows into the database</span>
    <span class="n">insertRowIntoData</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>


<span class="c1"># The function is annotated with an argument-free splitpoint, so its argument</span>
<span class="c1"># becomes one, thereby specifying that this function should run in one thread</span>
<span class="nd">@splitpoint</span>
<span class="k">def</span> <span class="nf">insertRowIntoData</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="n">factTable</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>


<span class="c1"># The CSV file is read by the main thread, then each row is transformed by</span>
<span class="c1"># one of five threads, before being added to the database by a sixth thread</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">sales</span><span class="p">:</span>
    <span class="n">performExpensiveTransformations</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>

<span class="c1"># To ensure that all splitpoint annotated functions are finished before</span>
<span class="c1"># the ETL flow is terminated, the function endsplits must be called as it</span>
<span class="c1"># joins all the threads created by splitpoints up to this point</span>
<span class="n">endsplits</span><span class="p">()</span>
<span class="n">conn</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>
<span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>The above example shows how to use splitpoints. Here, a very computationally
expensive function is annotated with a <code class="xref py py-attr docutils literal notranslate"><span class="pre">splitpoint</span></code> which is given the
argument five, allowing five processes to run the function at the same time. The
second <code class="xref py py-attr docutils literal notranslate"><span class="pre">splitpoint</span></code> without an argument ensures that only one process is
allowed to execute that function at a time, so even though it is called from
<code class="xref py py-func docutils literal notranslate"><span class="pre">performExpensiveTransformation()</span></code> only one process can insert rows into
the fact table at the same time. Should the operations on the fact table become
a bottleneck, it could be partitioned using <a class="reference internal" href="../api/tables.html#pygrametl.tables.FactTablePartitioner" title="pygrametl.tables.FactTablePartitioner"><code class="xref py py-class docutils literal notranslate"><span class="pre">FactTablePartitioner</span></code></a>. To
ensure that all splitpoints have finished execution, the function
<a class="reference internal" href="../api/parallel.html#pygrametl.parallel.endsplits" title="pygrametl.parallel.endsplits"><code class="xref py py-func docutils literal notranslate"><span class="pre">endsplits()</span></code></a> is executed, which joins all splitpoints, before the database
connection is closed.</p>
<p>As splitpoint annotated functions run in separate processes, any values they
return are not available to the process calling them. To work around this
restriction a queue can be passed as an argument to <code class="xref py py-attr docutils literal notranslate"><span class="pre">splitpoint</span></code> in which
the split function’s returned values will be added.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pygrametl.datasources</span> <span class="kn">import</span> <span class="n">CSVSource</span>
<span class="kn">from</span> <span class="nn">pygrametl.parallel</span> <span class="kn">import</span> <span class="n">splitpoint</span><span class="p">,</span> <span class="n">endsplits</span>
<span class="kn">from</span> <span class="nn">pygrametl.jythonmultiprocessing</span> <span class="kn">import</span> <span class="n">Queue</span>

<span class="n">queue</span> <span class="o">=</span> <span class="n">Queue</span><span class="p">()</span>
<span class="n">sales</span> <span class="o">=</span> <span class="n">CSVSource</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="nb">open</span><span class="p">(</span><span class="s1">&#39;sales.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">),</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>


<span class="c1"># A queue is passed to the decorator, which uses it to store return values</span>
<span class="nd">@splitpoint</span><span class="p">(</span><span class="n">instances</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">queue</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">expensiveReturningOperation</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>

    <span class="c1"># Some special value, in this case None, is used to indicate that no</span>
    <span class="c1"># more data will be given to the queue and that processing can continue</span>
    <span class="k">if</span> <span class="n">row</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="c1"># Returned values are automatically added to the queue for other to use</span>
    <span class="k">return</span> <span class="n">row</span>


<span class="c1"># Each row in the sales.csv is extracted and passed to the function</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">sales</span><span class="p">:</span>
    <span class="n">expensiveReturningOperation</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>

<span class="c1"># A simple sentinel value can be used to indicate that all rows have been</span>
<span class="c1"># processed and that the loop using the results below can break</span>
<span class="n">expensiveReturningOperation</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>

<span class="c1"># A infinite loop is used to process the returned values as the number of</span>
<span class="c1"># returned rows are unknown, so a sentinel value and a break is used instead</span>
<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
    <span class="c1"># Extracts the processed row returned by the annotated function, a</span>
    <span class="c1"># simple sentinel value is used to indicate when the processing is done</span>
    <span class="n">elem</span> <span class="o">=</span> <span class="n">queue</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">elem</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">break</span>

    <span class="c1"># Use the returned elements after the sentinel check to prevent errors</span>
    <span class="c1"># ......</span>

<span class="c1"># To ensure that all splitpoint annotated functions are finished before</span>
<span class="c1"># the ETL flow is terminated, the function endsplits must be called as it</span>
<span class="c1"># joins all the process created by splitpoints up to this point</span>
<span class="n">endsplits</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="flows">
<h2>Flows<a class="headerlink" href="#flows" title="Permalink to this heading">¶</a></h2>
<p>Another way to parallelize transformations is to use flows. In pygrametl, a flow
is a sequence of functions with the same interface, each running in its own
separate process, and where each function calls the next function in the
sequence. A flow can be created from multiple different functions using the
<a class="reference internal" href="../api/parallel.html#pygrametl.parallel.createflow" title="pygrametl.parallel.createflow"><code class="xref py py-func docutils literal notranslate"><span class="pre">createflow()</span></code></a> function. After a flow is created it can be called just like
any other function. Internally, the arguments are passed from the first function
to the last. While the arguments are passed to the functions, any returned
values are ignored. Unlike <a class="reference internal" href="../api/parallel.html#pygrametl.parallel.splitpoint" title="pygrametl.parallel.splitpoint"><code class="xref py py-func docutils literal notranslate"><span class="pre">splitpoint()</span></code></a>, arguments are passed in batches
and not as single values to reduce the overhead of synchronization.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pygrametl.tables</span> <span class="kn">import</span> <span class="n">Dimension</span>
<span class="kn">from</span> <span class="nn">pygrametl.datasources</span> <span class="kn">import</span> <span class="n">CSVSource</span>
<span class="kn">from</span> <span class="nn">pygrametl.parallel</span> <span class="kn">import</span> <span class="n">splitpoint</span><span class="p">,</span> <span class="n">endsplits</span><span class="p">,</span> <span class="n">createflow</span>
<span class="kn">from</span> <span class="nn">pygrametl.JDBCConnectionWrapper</span> <span class="kn">import</span> <span class="n">JDBCConnectionWrapper</span>

<span class="c1"># JDBC and Jython are used as threads usually provide better performance</span>
<span class="kn">import</span> <span class="nn">java.sql.DriverManager</span>
<span class="n">jconn</span> <span class="o">=</span> <span class="n">java</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">DriverManager</span><span class="o">.</span><span class="n">getConnection</span><span class="p">(</span>
    <span class="s2">&quot;jdbc:postgresql://localhost/dw?user=dwuser&amp;password=dwpass&quot;</span><span class="p">)</span>

<span class="n">conn</span> <span class="o">=</span> <span class="n">JDBCConnectionWrapper</span><span class="p">(</span><span class="n">jdbcconn</span><span class="o">=</span><span class="n">jconn</span><span class="p">)</span>

<span class="n">products</span> <span class="o">=</span> <span class="n">CSVSource</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="nb">open</span><span class="p">(</span><span class="s1">&#39;product.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">),</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>

<span class="n">productDimension</span> <span class="o">=</span> <span class="n">Dimension</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;product&#39;</span><span class="p">,</span>
        <span class="n">key</span><span class="o">=</span><span class="s1">&#39;productid&#39;</span><span class="p">,</span>
        <span class="n">attributes</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;price&#39;</span><span class="p">],</span>
        <span class="n">lookupatts</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">])</span>


<span class="c1"># Two functions are defined to transform the information in product.csv</span>
<span class="k">def</span> <span class="nf">normaliseProductNames</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="c1"># Expensive operations should be performed in a flow, this example is</span>
    <span class="c1"># simple, so the performance gain is negated by the synchronization</span>
    <span class="n">row</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">convertPriceToThousands</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="c1"># Expensive operations should be performed in a flow, this example is</span>
    <span class="c1"># simple, so the performance gain is negated by the synchronization</span>
    <span class="n">row</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">])</span> <span class="o">/</span> <span class="mi">1000</span>


<span class="c1"># A flow is created from the two functions defined above, this flow can then</span>
<span class="c1"># be called just like any other functions despite being parallelized</span>
<span class="n">flow</span> <span class="o">=</span> <span class="n">createflow</span><span class="p">(</span><span class="n">normaliseProductNames</span><span class="p">,</span> <span class="n">convertPriceToThousands</span><span class="p">)</span>


<span class="c1"># The data is read from product.csv in a splitpoint so the main process</span>
<span class="c1"># does not have to both read the input data and load it into the table</span>
<span class="nd">@splitpoint</span>
<span class="k">def</span> <span class="nf">producer</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">products</span><span class="p">:</span>
        <span class="n">flow</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>

    <span class="c1"># The flow should be closed when there is no more data available,</span>
    <span class="c1"># this means no more data is accepted but the computations will finish</span>
    <span class="n">flow</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>


<span class="c1"># The producer is called and the separate process starts to read the input</span>
<span class="n">producer</span><span class="p">()</span>

<span class="c1"># The simplest way to extract rows from a flow is just to iterate over it,</span>
<span class="c1"># however additional functions to get the results as a list are available</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">flow</span><span class="p">:</span>
    <span class="n">productDimension</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
<span class="n">endsplits</span><span class="p">()</span>
<span class="n">conn</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>
</pre></div>
</div>
<p>A flow is used in the above example to combine multiple functions, each
transforming the rows from product.csv. By creating a flow with these functions,
a process is created for each to increase the ETL flows throughput. The overhead
of transferring data between the functions is reduced through batching. Rows
are provided to the flow in function <code class="xref py py-func docutils literal notranslate"><span class="pre">producer()</span></code>, which runs in a separate
process using a splitpoint so the main process can load the transformed rows
into the database by iterating over the flow.</p>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">pygrametl</a></h1>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quickstart/install.html">Install Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart/beginner.html">Beginner Guide</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="database.html">Database</a></li>
<li class="toctree-l1"><a class="reference internal" href="datasources.html">Data Sources</a></li>
<li class="toctree-l1"><a class="reference internal" href="dimensions.html">Dimensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="facttables.html">Fact Tables</a></li>
<li class="toctree-l1"><a class="reference internal" href="bulkloading.html">Bulk Loading</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="jython.html">Jython</a></li>
<li class="toctree-l1"><a class="reference internal" href="testing.html">Testing</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/pygrametl.html">pygrametl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/datasources.html">datasources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/tables.html">tables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/parallel.html">parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/jdbcconnectionwrapper.html">JDBCConnectionWrapper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/jythonmultiprocessing.html">jythonmultiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/aggregators.html">aggregators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/steps.html">steps</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/fifodict.html">FIFODict</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/drawntabletesting.html">drawntabletesting</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="bulkloading.html" title="previous chapter">Bulk Loading</a></li>
      <li>Next: <a href="jython.html" title="next chapter">Jython</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2009 - 2022, Aalborg University.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 5.3.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/examples/parallel.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>